---
title: Inference
---

<!-- THIS FILE IS AUTO-GENERATED BY website/scripts/generate-model-docs.js. DO NOT EDIT MANUALLY. -->

# Inference

Use `inference/<model>` with VoltAgent's model router.

## Quick start

```ts
import { Agent } from "@voltagent/core";

const agent = new Agent({
  name: "inference-agent",
  instructions: "You are a helpful assistant",
  model: "inference/google/gemma-3",
});
```

## Environment variables

- `INFERENCE_API_KEY`

## Provider package

`@ai-sdk/openai-compatible`

This provider uses the OpenAI-compatible adapter.

## Default base URL

`https://inference.net/v1`

You can override the base URL by setting `INFERENCE_BASE_URL`.

## Provider docs

- https://inference.net/models

## Models

<details>
  <summary>Show models (9)</summary>

- google/gemma-3
- meta/llama-3.1-8b-instruct
- meta/llama-3.2-11b-vision-instruct
- meta/llama-3.2-1b-instruct
- meta/llama-3.2-3b-instruct
- mistral/mistral-nemo-12b-instruct
- osmosis/osmosis-structure-0.6b
- qwen/qwen-2.5-7b-vision-instruct
- qwen/qwen3-embedding-4b

</details>
